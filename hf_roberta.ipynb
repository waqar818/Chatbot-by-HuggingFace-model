{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing Haystack\n"
      ],
      "metadata": {
        "id": "uQhKmazRebeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78NdjejVeUSw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(1)"
      ],
      "metadata": {
        "id": "GVdPWX6lezSl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "IXjItOxRe6oY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ3155oWe-wI",
        "outputId": "6bc19fe6-52c4-4245-fba2-8348ba2e7e2e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_dir = \"Data\""
      ],
      "metadata": {
        "id": "kRmMScQFfC62"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from haystack.pipelines.standard_pipelines import TextIndexingPipeline\n",
        "\n",
        "files_to_index = [doc_dir + \"/\" + f for f in os.listdir(doc_dir)]\n",
        "indexing_pipeline = TextIndexingPipeline(document_store)\n",
        "indexing_pipeline.run_batch(file_paths=files_to_index)\n"
      ],
      "metadata": {
        "id": "5kGfkTBYZ1Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever = BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "Rti4mJHbZ4MH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-R8TyL3Z8d5",
        "outputId": "fc6e5ac3-0583-41fa-e610-4754e864336e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n",
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "metadata": {
        "id": "sX4uPlcEaAT6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "KAhdu8zTlon_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "oYAHHTwrlmZn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = pipe.run(\n",
        "#     query=\"What are some example of cardiovascular exercises?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        "# )"
      ],
      "metadata": {
        "id": "-LKITc-RaC_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "\n",
        "# pprint(prediction)"
      ],
      "metadata": {
        "id": "uXBQQCAsaInF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from haystack.utils import print_answers\n",
        "\n",
        "# print_answers(prediction, details=\"all\")  ## Choose from `minimum`, `medium`, and `all`"
      ],
      "metadata": {
        "id": "Bg647oTRi3BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_highest_score_answer(prediction):\n",
        "    answers = prediction['answers']\n",
        "    highest_score = max(answer.score for answer in answers)\n",
        "    highest_score_answers = [answer for answer in answers if answer.score == highest_score]\n",
        "    return highest_score_answers\n"
      ],
      "metadata": {
        "id": "cERPcIjUFenn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# highest_score_answers = get_highest_score_answer(prediction)\n",
        "# for answer in highest_score_answers:\n",
        "#     print(answer.answer)\n"
      ],
      "metadata": {
        "id": "Zg8v_xDhFiCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(query):\n",
        "    prediction = pipe.run(query=query, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n",
        "    highest_score_answers = get_highest_score_answer(prediction)\n",
        "    return [answer.answer for answer in highest_score_answers]\n"
      ],
      "metadata": {
        "id": "gmYogom0lOTY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=answer_question,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Question Answering Chatbot\",\n",
        "    description=\"Enter a question and get the answer from the pre-trained model.\",\n",
        ")"
      ],
      "metadata": {
        "id": "cWHXJvK4lQ0P"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Zo0ph1y-lSsH",
        "outputId": "e54a4444-404f-43e4-aefa-60a68225d151"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}